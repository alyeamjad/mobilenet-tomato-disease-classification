{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh-fwMW1zLzZ",
        "outputId": "b067a245-bfcf-4faf-cf45-ceeaa8491255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/Tomato_leafs/plant disease\""
      ],
      "metadata": {
        "id": "2qPn6qQQz_h_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir='/content/drive/MyDrive/Tomato_leafs/plant disease/train'"
      ],
      "metadata": {
        "id": "N9hiLc4n0BrD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir='/content/drive/MyDrive/Tomato_leafs/plant disease/valid'"
      ],
      "metadata": {
        "id": "aJy0-uWE0Dnx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
        "test=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "E-nHvDf60F-V"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindata=train.flow_from_directory(train_dir,target_size=(128,128),batch_size=32,class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0uMk7v30IzD",
        "outputId": "ae7d0f0b-7b78-4eb6-9c7c-f3eae6dfc187"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1555 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdata=test.flow_from_directory(test_dir,target_size=(128,128),batch_size=32,class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5nWvZov0O9K",
        "outputId": "5a172d09-64c3-489f-ba87-3967342a6cf8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 473 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def depthwise_separable_conv(input, filters, kernel_size, strides):\n",
        "    x = tf.keras.layers.DepthwiseConv2D(kernel_size=kernel_size, strides=strides, padding='same')(input)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Conv2D(filters=filters, kernel_size=1, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def mobilenet(input_shape, num_classes):\n",
        "    input = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Conv2D(32, kernel_size=3, strides=(2,2), padding='same')(input)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "\n",
        "    x = depthwise_separable_conv(x, filters=64, kernel_size=3, strides=(1,1))\n",
        "    x = depthwise_separable_conv(x, filters=128, kernel_size=3, strides=(2,2))\n",
        "    x = depthwise_separable_conv(x, filters=128, kernel_size=3, strides=(1,1))\n",
        "    x = depthwise_separable_conv(x, filters=256, kernel_size=3, strides=(2,2))\n",
        "    x = depthwise_separable_conv(x, filters=256, kernel_size=3, strides=(1,1))\n",
        "    x = depthwise_separable_conv(x, filters=512, kernel_size=3, strides=(2,2))\n",
        "\n",
        "    for i in range(5):\n",
        "        x = depthwise_separable_conv(x, filters=512, kernel_size=3, strides=(1,1))\n",
        "\n",
        "    x = depthwise_separable_conv(x, filters=1024, kernel_size=3, strides=(2,2))\n",
        "    x = depthwise_separable_conv(x, filters=1024, kernel_size=3, strides=(1,1))\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    output = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=input, outputs=output)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "VPu7L1JX0SyU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = mobilenet(input_shape=(224, 224, 3), num_classes=5)\n"
      ],
      "metadata": {
        "id": "JhrevkU73V2U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.optimizers import Adam\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jq63Z3TC4CLp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var=model.fit(traindata,validation_data=testdata,epochs=5,batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAI_RaLQ4T7z",
        "outputId": "bcaea55e-7735-45dd-83f9-4a731a59cd9e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "49/49 [==============================] - 360s 7s/step - loss: 1.4785 - accuracy: 0.3222 - val_loss: 1.6415 - val_accuracy: 0.2093\n",
            "Epoch 2/5\n",
            "49/49 [==============================] - 12s 236ms/step - loss: 1.3721 - accuracy: 0.3820 - val_loss: 1.7253 - val_accuracy: 0.1332\n",
            "Epoch 3/5\n",
            "49/49 [==============================] - 12s 249ms/step - loss: 1.2515 - accuracy: 0.4695 - val_loss: 1.8644 - val_accuracy: 0.1332\n",
            "Epoch 4/5\n",
            "49/49 [==============================] - 12s 250ms/step - loss: 1.1371 - accuracy: 0.5023 - val_loss: 2.0400 - val_accuracy: 0.1332\n",
            "Epoch 5/5\n",
            "49/49 [==============================] - 12s 247ms/step - loss: 0.9798 - accuracy: 0.5910 - val_loss: 2.2661 - val_accuracy: 0.1332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cx99yrUi4Vai"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}